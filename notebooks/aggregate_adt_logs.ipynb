{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths to data and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 64 result folders\n",
      "Found 16 gg result folders\n"
     ]
    }
   ],
   "source": [
    "# TODO: Change the following paths according to your own setup\n",
    "DATA_ROOT = \"/rvl-home/guqiao/ldata/adt_processed/\"\n",
    "RESULT_ROOT = \"/rvl-home/guqiao/src/gaussian_splatting/output/adt_v3/\"\n",
    "GG_RESULT_ROOT = \"/rvl-home/guqiao/src/gaussian-grouping/output/gg_adt_v2\"\n",
    "\n",
    "RESULT_ROOT = Path(RESULT_ROOT)\n",
    "DATA_ROOT = Path(DATA_ROOT)\n",
    "GG_RESULT_ROOT = Path(GG_RESULT_ROOT)\n",
    "\n",
    "result_folders = glob(str(RESULT_ROOT / \"*\" / \"*\"))\n",
    "print(f\"Found {len(result_folders)} result folders\")\n",
    "\n",
    "gg_result_folders = glob(str(GG_RESULT_ROOT / \"*\"))\n",
    "print(f\"Found {len(gg_result_folders)} gg result folders\")\n",
    "\n",
    "# subset_shown = \"1-valid\"  # from the seen subset\n",
    "subset_shown = \"2-test\"   # from the noval subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and aggregate the 2D segmentation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subset           2-test                                                 \n",
      "eval_mode          1-gt                 2-cross-gt_0.6_5                \n",
      "seg_type       1-static 2-dynamic 3-all         1-static 2-dynamic 3-all\n",
      "exp_name                                                                \n",
      "1-sam             54.51     32.77 50.69              NaN       NaN   NaN\n",
      "2-gg              35.68     30.76 34.81            23.79     11.33 21.58\n",
      "3-3dgs            55.67     39.61 52.86            51.29     18.67 45.49\n",
      "4-dynamic 3dgs    54.23     38.62 51.49            51.10     18.02 45.22\n",
      "5-ours            58.15     37.74 54.57            55.27     19.14 48.84\n",
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      "subset & \\multicolumn{6}{r}{2-test} \\\\\n",
      "eval_mode & \\multicolumn{3}{r}{1-gt} & \\multicolumn{3}{r}{2-cross-gt_0.6_5} \\\\\n",
      "seg_type & 1-static & 2-dynamic & 3-all & 1-static & 2-dynamic & 3-all \\\\\n",
      "exp_name &  &  &  &  &  &  \\\\\n",
      "\\midrule\n",
      "1-sam & 54.51 & 32.77 & 50.69 & NaN & NaN & NaN \\\\\n",
      "2-gg & 35.68 & 30.76 & 34.81 & 23.79 & 11.33 & 21.58 \\\\\n",
      "3-3dgs & 55.67 & 39.61 & 52.86 & 51.29 & 18.67 & 45.49 \\\\\n",
      "4-dynamic 3dgs & 54.23 & 38.62 & 51.49 & 51.10 & 18.02 & 45.22 \\\\\n",
      "5-ours & 58.15 & 37.74 & 54.57 & 55.27 & 19.14 & 48.84 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfs_all = []\n",
    "\n",
    "'''\n",
    "Load our own results\n",
    "'''\n",
    "for result_folder in result_folders:\n",
    "    exp_name = result_folder.split(\"/\")[-1]\n",
    "    scene_name = result_folder.split(\"/\")[-2]\n",
    "    \n",
    "    data_folder = DATA_ROOT / scene_name\n",
    "    instance_json_path = data_folder / \"instances.json\"\n",
    "    instance_json = json.load(open(instance_json_path))\n",
    "    df_instance = pd.DataFrame([\n",
    "        {\n",
    "            \"instance_id\": v['instance_id'],\n",
    "            \"instance_name\": v[\"instance_name\"],\n",
    "            \"category\": v[\"category\"],\n",
    "            \"category_uid\": v[\"category_uid\"],\n",
    "        } for k, v in instance_json.items()\n",
    "    ])\n",
    "    \n",
    "    # Add the normal evaluation\n",
    "    log_file_paths = glob(str(Path(result_folder) / \"2dseg_eval\" / \"*.csv\"))\n",
    "    \n",
    "    for log_file_path in log_file_paths:\n",
    "        log_file_name = os.path.basename(log_file_path)[:-4]\n",
    "        subset = log_file_name.split(\"_logs\")[0]\n",
    "        if \"_logs_\" in log_file_name:\n",
    "            eval_mode = log_file_name.split(\"_logs_\")[1]\n",
    "        else:\n",
    "            eval_mode = \"default\"\n",
    "        if \"gt_\" in eval_mode:\n",
    "            eval_mode = \"gt\"\n",
    "        df_log = pd.read_csv(log_file_path)\n",
    "        df_log[\"exp_name\"] = exp_name\n",
    "        df_log[\"scene_name\"] = scene_name\n",
    "        df_log['subset'] = subset\n",
    "        df_log['eval_mode'] = eval_mode\n",
    "        df_log = df_log.rename(columns={\"seg_id\": \"instance_id\"})\n",
    "        df_log = df_log.merge(df_instance, on=\"instance_id\", how=\"left\")\n",
    "\n",
    "        dfs_all.append(df_log)\n",
    "        \n",
    "    # Add the evaluation of SAM\n",
    "    log_file_paths = glob(str(Path(result_folder) / \"2dseg_eval_sam\" / \"*.csv\"))\n",
    "    for log_file_path in log_file_paths:\n",
    "        log_file_name = os.path.basename(log_file_path)[:-4]\n",
    "        subset = log_file_name.split(\"_logs\")[0]\n",
    "        if \"_logs_\" in log_file_name:\n",
    "            eval_mode = log_file_name.split(\"_logs_\")[1]\n",
    "        else:\n",
    "            eval_mode = \"default\"\n",
    "        df_log = pd.read_csv(log_file_path)\n",
    "        df_log[\"exp_name\"] = \"sam\"\n",
    "        df_log[\"scene_name\"] = scene_name\n",
    "        df_log['subset'] = subset\n",
    "        df_log['eval_mode'] = eval_mode\n",
    "        df_log = df_log.rename(columns={\"seg_id\": \"instance_id\"})\n",
    "        df_log = df_log.merge(df_instance, on=\"instance_id\", how=\"left\")\n",
    "\n",
    "        dfs_all.append(df_log)\n",
    "        \n",
    "    log_file_paths = glob(str(Path(result_folder) / \"2dseg_eval_cross\" / \"*.csv\"))\n",
    "    for log_file_path in log_file_paths:\n",
    "        log_file_name = os.path.basename(log_file_path)[:-4]\n",
    "        subset = log_file_name.split(\"_logs\")[0]\n",
    "        if \"_logs_\" in log_file_name:\n",
    "            eval_mode = log_file_name.split(\"_logs_\")[1]\n",
    "        else:\n",
    "            eval_mode = \"default\"\n",
    "        df_log = pd.read_csv(log_file_path)\n",
    "        df_log[\"exp_name\"] = exp_name\n",
    "        df_log[\"scene_name\"] = scene_name\n",
    "        df_log['subset'] = subset\n",
    "        df_log['eval_mode'] = \"cross-\" + eval_mode\n",
    "        df_log = df_log.rename(columns={\"seg_id\": \"instance_id\"})\n",
    "        df_log = df_log.merge(df_instance, on=\"instance_id\", how=\"left\")\n",
    "\n",
    "        dfs_all.append(df_log)\n",
    "        \n",
    "'''\n",
    "Load the Gaussian Grouping results\n",
    "'''\n",
    "for result_folder in gg_result_folders:\n",
    "    exp_name = \"gaussian_grouping\"\n",
    "    scene_name = result_folder.split(\"/\")[-1]\n",
    "    \n",
    "    data_folder = DATA_ROOT / scene_name\n",
    "    instance_json_path = data_folder / \"instances.json\"\n",
    "    instance_json = json.load(open(instance_json_path))\n",
    "    df_instance = pd.DataFrame([\n",
    "        {\n",
    "            \"instance_id\": v['instance_id'],\n",
    "            \"instance_name\": v[\"instance_name\"],\n",
    "            \"category\": v[\"category\"],\n",
    "            \"category_uid\": v[\"category_uid\"],\n",
    "        } for k, v in instance_json.items()\n",
    "    ])\n",
    "    \n",
    "    # Add the normal evaluation\n",
    "    log_file_paths = glob(str(Path(result_folder) / \"2dseg_eval\" / \"*.csv\"))\n",
    "    for log_file_path in log_file_paths:\n",
    "        log_file_name = os.path.basename(log_file_path)[:-4]\n",
    "        subset = log_file_name.split(\"_logs\")[0]\n",
    "        if \"_logs_\" in log_file_name:\n",
    "            eval_mode = log_file_name.split(\"_logs_\")[1]\n",
    "        else:\n",
    "            eval_mode = \"default\"\n",
    "        if \"gt_\" in eval_mode:\n",
    "            eval_mode = \"gt\"\n",
    "        df_log = pd.read_csv(log_file_path)\n",
    "        df_log[\"exp_name\"] = exp_name\n",
    "        df_log[\"scene_name\"] = scene_name\n",
    "        df_log['subset'] = subset\n",
    "        df_log['eval_mode'] = eval_mode\n",
    "        df_log = df_log.rename(columns={\"seg_id\": \"instance_id\"})\n",
    "        df_log = df_log.merge(df_instance, on=\"instance_id\", how=\"left\")\n",
    "\n",
    "        dfs_all.append(df_log)\n",
    "        \n",
    "    log_file_paths = glob(str(Path(result_folder) / \"2dseg_eval_cross\" / \"*.csv\"))\n",
    "    for log_file_path in log_file_paths:\n",
    "        log_file_name = os.path.basename(log_file_path)[:-4]\n",
    "        subset = log_file_name.split(\"_logs\")[0]\n",
    "        if \"_logs_\" in log_file_name:\n",
    "            eval_mode = log_file_name.split(\"_logs_\")[1]\n",
    "        else:\n",
    "            eval_mode = \"default\"\n",
    "        df_log = pd.read_csv(log_file_path)\n",
    "        df_log[\"exp_name\"] = exp_name\n",
    "        df_log[\"scene_name\"] = scene_name\n",
    "        df_log['subset'] = subset\n",
    "        df_log['eval_mode'] = \"cross-\" + eval_mode\n",
    "        df_log = df_log.rename(columns={\"seg_id\": \"instance_id\"})\n",
    "        df_log = df_log.merge(df_instance, on=\"instance_id\", how=\"left\")\n",
    "\n",
    "        dfs_all.append(df_log)\n",
    "        \n",
    "\n",
    "df_all = pd.concat(dfs_all, axis=0)\n",
    "df_all = df_all.reset_index(drop=True)\n",
    "\n",
    "df = df_all\n",
    "\n",
    "df['exp_name'] = df['exp_name'].replace({\n",
    "    \"sam\": \"1-sam\",\n",
    "    \"gaussian_grouping\": \"2-gg\",\n",
    "    \"unc_2d_unet_baseline_contr16_thresh0.5\": \"3-3dgs\",\n",
    "    \"deform_def_contr16\": \"4-dynamic 3dgs\",\n",
    "    \"unc_2d_unet_sigmoid_contr16_thresh0.5\": \"5-ours\"\n",
    "})\n",
    "\n",
    "df['seg_type'] = df['seg_type'].replace({\n",
    "    \"static\": \"1-static\",\n",
    "    \"dynamic\": \"2-dynamic\",\n",
    "    \"all\": \"3-all\"\n",
    "})\n",
    "df['subset'] = df['subset'].replace({\n",
    "    \"valid\": \"1-valid\",\n",
    "    \"test\": \"2-test\"\n",
    "})\n",
    "\n",
    "df['eval_mode'] = df['eval_mode'].replace({\n",
    "    \"gt\": \"1-gt\",\n",
    "    \"cross-gt_0.6_5\": \"2-cross-gt_0.6_5\"\n",
    "})\n",
    "\n",
    "df = df[df['eval_mode'] != \"fixed_0.6\"]\n",
    "\n",
    "df = df[df['subset'].isin(['1-valid', '2-test'])]\n",
    "\n",
    "df_all_seg = df.groupby([\"subset\", \"exp_name\", \"eval_mode\"]).agg({\n",
    "    \"iou\": [\"mean\"],\n",
    "})\n",
    "df_all_seg.columns = df_all_seg.columns.droplevel(1)\n",
    "df_all_seg['iou'] = df_all_seg['iou'] * 100\n",
    "df_all_seg = df_all_seg.rename(columns={\"iou\": \"mIoU\"})\n",
    "df_all_seg = df_all_seg.reset_index()\n",
    "df_all_seg['seg_type'] = \"3-all\"\n",
    "\n",
    "\n",
    "df = df.groupby([\"subset\", \"exp_name\", \"eval_mode\", \"seg_type\"]).agg({\n",
    "    \"iou\": [\"mean\"],\n",
    "})\n",
    "# Drop the multi-level of columns\n",
    "df.columns = df.columns.droplevel(1)\n",
    "\n",
    "df['iou'] = df['iou'] * 100\n",
    "df = df.rename(columns={\"iou\": \"mIoU\"})\n",
    "df = df.reset_index()\n",
    "df = df[::-1]\n",
    "\n",
    "df = pd.concat([df_all_seg, df], axis=0)\n",
    "\n",
    "df = df[df['subset'] == subset_shown]\n",
    "df = df.sort_values(by=\"exp_name\", ascending=False)\n",
    "df = df.sort_values(by=[\"subset\", 'eval_mode', \"seg_type\"], ascending=True)\n",
    "# df = df.sort_values(by=, ascending=True)\n",
    "\n",
    "df_2dseg = df\n",
    "\n",
    "df = df.pivot(index=['exp_name'], columns=[\"subset\", 'eval_mode', \"seg_type\"], values=\"mIoU\")\n",
    "\n",
    "# display float with 2 decimal places\n",
    "with pd.option_context('display.float_format', '{:.2f}'.format):\n",
    "    print(df)\n",
    "\n",
    "print(df.to_latex(escape=False, float_format=\"%.2f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and aggregate 3D segmentation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subset                     test        \n",
      "seg_type                 static dynamic\n",
      "eval_mode exp_name                     \n",
      "cross-gt  2-3dgs          21.10   17.92\n",
      "          3-dynamic 3dgs  20.58   16.58\n",
      "          4-gg             7.48    5.64\n",
      "          5-ours          23.11   17.93\n",
      "gt        2-3dgs          17.01   15.02\n",
      "          3-dynamic 3dgs  15.96   16.91\n",
      "          4-gg             9.43    9.69\n",
      "          5-ours          17.75   16.79\n"
     ]
    }
   ],
   "source": [
    "# Aggregate the results for 3D bounding box evaluation\n",
    "dfs_all = []\n",
    "\n",
    "# Load our own model\n",
    "for result_folder in result_folders:\n",
    "    exp_name = result_folder.split(\"/\")[-1]\n",
    "    scene_name = result_folder.split(\"/\")[-2]\n",
    "    \n",
    "    data_folder = DATA_ROOT / scene_name\n",
    "    instance_json_path = data_folder / \"instances.json\"\n",
    "    instance_json = json.load(open(instance_json_path))\n",
    "    df_instance = pd.DataFrame([\n",
    "        {\n",
    "            \"instance_id\": v['instance_id'],\n",
    "            \"instance_name\": v[\"instance_name\"],\n",
    "            \"category\": v[\"category\"],\n",
    "            \"category_uid\": v[\"category_uid\"],\n",
    "        } for k, v in instance_json.items()\n",
    "    ])\n",
    "    \n",
    "    log_file_paths = glob(str(Path(result_folder) / \"3dbox_eval*\" / \"*.csv\"))\n",
    "    \n",
    "    for log_file_path in log_file_paths:\n",
    "        log_file_name = os.path.basename(log_file_path)[:-4]\n",
    "        subset = log_file_name.split(\"_logs\")[0]\n",
    "        eval_mode = log_file_name.split(\"_logs_\")[1]\n",
    "        \n",
    "        if \"gt_\" in eval_mode:\n",
    "            eval_mode = \"gt\"\n",
    "            \n",
    "        eval_folder_name = log_file_path.split(\"/\")[-2]\n",
    "        if \"cross\" in eval_folder_name:\n",
    "            eval_mode = \"cross-\" + eval_mode\n",
    "            \n",
    "        df_log = pd.read_csv(log_file_path)\n",
    "        df_log[\"exp_name\"] = exp_name\n",
    "        df_log[\"scene_name\"] = scene_name\n",
    "        df_log['subset'] = subset\n",
    "        df_log['eval_mode'] = eval_mode\n",
    "        df_log = df_log.rename(columns={\"seg_id\": \"instance_id\"})\n",
    "        df_log = df_log.merge(df_instance, on=\"instance_id\", how=\"left\")\n",
    "\n",
    "        dfs_all.append(df_log)\n",
    "        \n",
    "# Load the Gaussian Grouping results\n",
    "for result_folder in gg_result_folders:\n",
    "    exp_name = \"gaussian_grouping\"\n",
    "    scene_name = result_folder.split(\"/\")[-1]\n",
    "    \n",
    "    data_folder = DATA_ROOT / scene_name\n",
    "    instance_json_path = data_folder / \"instances.json\"\n",
    "    instance_json = json.load(open(instance_json_path))\n",
    "    df_instance = pd.DataFrame([\n",
    "        {\n",
    "            \"instance_id\": v['instance_id'],\n",
    "            \"instance_name\": v[\"instance_name\"],\n",
    "            \"category\": v[\"category\"],\n",
    "            \"category_uid\": v[\"category_uid\"],\n",
    "        } for k, v in instance_json.items()\n",
    "    ])\n",
    "    \n",
    "    log_file_paths = glob(str(Path(result_folder) / \"3dbox_eval*\" / \"*.csv\"))\n",
    "    \n",
    "    for log_file_path in log_file_paths:\n",
    "        log_file_name = os.path.basename(log_file_path)[:-4]\n",
    "        subset = log_file_name.split(\"_logs\")[0]\n",
    "        eval_mode = log_file_name.split(\"_logs_\")[1]\n",
    "        \n",
    "        if \"gt_\" in eval_mode:\n",
    "            eval_mode = \"gt\"\n",
    "            \n",
    "        eval_folder_name = log_file_path.split(\"/\")[-2]\n",
    "        if \"cross\" in eval_folder_name:\n",
    "            eval_mode = \"cross-\" + eval_mode\n",
    "            \n",
    "        df_log = pd.read_csv(log_file_path)\n",
    "        df_log[\"exp_name\"] = exp_name\n",
    "        df_log[\"scene_name\"] = scene_name\n",
    "        df_log['subset'] = subset\n",
    "        df_log['eval_mode'] = eval_mode\n",
    "        df_log = df_log.rename(columns={\"seg_id\": \"instance_id\"})\n",
    "        df_log = df_log.merge(df_instance, on=\"instance_id\", how=\"left\")\n",
    "\n",
    "        dfs_all.append(df_log)\n",
    "    \n",
    "        \n",
    "df_all = pd.concat(dfs_all, axis=0)\n",
    "df_all = df_all.reset_index(drop=True)\n",
    "\n",
    "df = df_all\n",
    "\n",
    "df['exp_name'] = df['exp_name'].replace({\n",
    "    \"sam\": \"1-sam\",\n",
    "    \"unc_2d_unet_baseline_contr16_thresh0.5\": \"2-3dgs\",\n",
    "    \"deform_def_contr16\": \"3-dynamic 3dgs\",\n",
    "    \"gaussian_grouping\": \"4-gg\",\n",
    "    \"unc_2d_unet_sigmoid_contr16_thresh0.5\": \"5-ours\"\n",
    "})\n",
    "\n",
    "df = df[df['subset'].isin(['valid', 'test'])]\n",
    "\n",
    "df = df.groupby([\"subset\", \"exp_name\", \"eval_mode\", \"seg_type\"]).agg({\n",
    "    \"iou\": [\"mean\"],\n",
    "})\n",
    "# Drop the multi-level of columns\n",
    "df.columns = df.columns.droplevel(1)\n",
    "\n",
    "df['iou'] = df['iou'] * 100\n",
    "df = df.rename(columns={\"iou\": \"mIoU\"})\n",
    "df = df.reset_index()\n",
    "df = df[::-1]\n",
    "df = df.sort_values(by=\"exp_name\", ascending=False)\n",
    "df = df.sort_values(by=[\"subset\", \"seg_type\"], ascending=False)\n",
    "\n",
    "df = df.pivot(index=['eval_mode', 'exp_name'], columns=[\"subset\", \"seg_type\"], values=\"mIoU\")\n",
    "\n",
    "# display float with 2 decimal places\n",
    "with pd.option_context('display.float_format', '{:.2f}'.format):\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and aggregate photometric metrics (PSNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subset           2-test                \n",
      "seg_type       1-static 2-dynamic 3-all\n",
      "exp_name                               \n",
      "2-gg              21.29     14.99 19.97\n",
      "3-3dgs            21.37     15.32 20.16\n",
      "4-dynamic 3dgs    21.16     15.39 19.93\n",
      "5-ours            22.14     14.37 20.28\n",
      "\\begin{tabular}{llll}\n",
      "\\toprule\n",
      "subset & \\multicolumn{3}{r}{2-test} \\\\\n",
      "seg_type & 1-static & 2-dynamic & 3-all \\\\\n",
      "exp_name &  &  &  \\\\\n",
      "\\midrule\n",
      "2-gg & 21.29 & 14.99 & 19.97 \\\\\n",
      "3-3dgs & 21.37 & 15.32 & 20.16 \\\\\n",
      "4-dynamic 3dgs & 21.16 & 15.39 & 19.93 \\\\\n",
      "5-ours & 22.14 & 14.37 & 20.28 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aggregate the PSNR evaluation logs\n",
    "dfs_all = []\n",
    "for result_folder in result_folders:\n",
    "    exp_name = result_folder.split(\"/\")[-1]\n",
    "    scene_name = result_folder.split(\"/\")[-2]\n",
    "    \n",
    "    log_file_paths = glob(str(Path(result_folder) / \"eval_logs_*.csv\"))\n",
    "    \n",
    "    for log_file_path in log_file_paths:\n",
    "        log_file_name = os.path.basename(log_file_path)[:-4]\n",
    "        subset = log_file_name.split(\"_logs_\")[1]\n",
    "        \n",
    "        if subset not in ['valid', 'test']:\n",
    "            continue\n",
    "        \n",
    "        df_log = pd.read_csv(log_file_path)\n",
    "        df_log[\"exp_name\"] = exp_name\n",
    "        df_log[\"scene_name\"] = scene_name\n",
    "        df_log['subset'] = subset\n",
    "        \n",
    "        dfs_all.append(df_log)\n",
    "        \n",
    "for result_folder in gg_result_folders:\n",
    "    exp_name = \"gaussian_grouping\"\n",
    "    scene_name = result_folder.split(\"/\")[-1]\n",
    "    \n",
    "    log_file_paths = glob(str(Path(result_folder) / \"eval_logs_*.csv\"))\n",
    "    \n",
    "    for log_file_path in log_file_paths:\n",
    "        log_file_name = os.path.basename(log_file_path)[:-4]\n",
    "        subset = log_file_name.split(\"_logs_\")[1]\n",
    "        \n",
    "        if subset not in ['valid', 'test']:\n",
    "            continue\n",
    "        \n",
    "        df_log = pd.read_csv(log_file_path)\n",
    "        df_log[\"exp_name\"] = exp_name\n",
    "        df_log[\"scene_name\"] = scene_name\n",
    "        df_log['subset'] = subset\n",
    "        \n",
    "        dfs_all.append(df_log)\n",
    "        \n",
    "df_all = pd.concat(dfs_all, axis=0)\n",
    "df_all = df_all.reset_index(drop=True)\n",
    "\n",
    "df = df_all\n",
    "df['exp_name'] = df['exp_name'].replace({\n",
    "    \"sam\": \"1-sam\",\n",
    "    \"gaussian_grouping\": \"2-gg\",\n",
    "    \"unc_2d_unet_baseline_contr16_thresh0.5\": \"3-3dgs\",\n",
    "    \"deform_def_contr16\": \"4-dynamic 3dgs\",\n",
    "    \"unc_2d_unet_sigmoid_contr16_thresh0.5\": \"5-ours\"\n",
    "})\n",
    "\n",
    "df = df[~df['exp_name'].isin([\"vanilla_vanilla\"])]\n",
    "\n",
    "df = df.groupby([\"scene_name\", \"exp_name\", \"subset\"]).agg({\n",
    "    \"static_psnr\": [\"mean\"],\n",
    "    \"dyna_psnr\": [\"mean\"],\n",
    "    \"psnr\": [\"mean\"],\n",
    "})\n",
    "df.columns = df.columns.droplevel(1)\n",
    "\n",
    "df = df.groupby([\"exp_name\", \"subset\"]).agg({\n",
    "    \"static_psnr\": [\"mean\"],\n",
    "    \"dyna_psnr\": [\"mean\"],\n",
    "    \"psnr\": [\"mean\"],\n",
    "})\n",
    "df.columns = df.columns.droplevel(1)\n",
    "\n",
    "df = df.reset_index()\n",
    "df = df.melt(id_vars=['exp_name', 'subset'], value_vars=df.columns)\n",
    "df = df.rename(columns={\"variable\": \"seg_type\", \"value\": \"psnr\"})\n",
    "df['seg_type'] = df['seg_type'].replace({\n",
    "    \"static_psnr\": \"1-static\",\n",
    "    \"dyna_psnr\": \"2-dynamic\",\n",
    "    \"psnr\": \"3-all\"\n",
    "})\n",
    "df['subset'] = df['subset'].replace({\n",
    "    \"valid\": \"1-valid\",\n",
    "    \"test\": \"2-test\"\n",
    "})\n",
    "df['eval_mode'] = \"3-psnr\"\n",
    "df = df[df['subset'] == subset_shown]\n",
    "df = df.sort_values(by=[\"subset\", \"seg_type\"], ascending=True)\n",
    "\n",
    "df_psnr = df\n",
    "\n",
    "df = df.pivot(index=['exp_name'], columns=[\"subset\", 'seg_type'], values=\"psnr\")\n",
    "\n",
    "# Find a row where \"static_psnr\", \"dyna_psnr\" or \"psnr\" is a string\n",
    "# df = df[\n",
    "#     (df['static_psnr'].apply(lambda x: isinstance(x, str))) |\n",
    "#     (df['dyna_psnr'].apply(lambda x: isinstance(x, str))) |\n",
    "#     (df['psnr'].apply(lambda x: isinstance(x, str))) \n",
    "# ]\n",
    "\n",
    "with pd.option_context('display.float_format', '{:.2f}'.format):\n",
    "    print(df)\n",
    "\n",
    "print(df.to_latex(escape=False, float_format=\"%.2f\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate 2D segmentation and PSNR results and make Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subset           2-test                                                   \\\n",
      "eval_mode          1-gt                 2-cross-gt_0.6_5                   \n",
      "seg_type       1-static 2-dynamic 3-all         1-static 2-dynamic 3-all   \n",
      "exp_name                                                                   \n",
      "1-sam             54.51     32.77 50.69              NaN       NaN   NaN   \n",
      "2-gg              35.68     30.76 34.81            23.79     11.33 21.58   \n",
      "3-3dgs            55.67     39.61 52.86            51.29     18.67 45.49   \n",
      "4-dynamic 3dgs    54.23     38.62 51.49            51.10     18.02 45.22   \n",
      "5-ours            58.15     37.74 54.57            55.27     19.14 48.84   \n",
      "\n",
      "subset                                   \n",
      "eval_mode        3-psnr                  \n",
      "seg_type       1-static 2-dynamic 3-all  \n",
      "exp_name                                 \n",
      "1-sam               NaN       NaN   NaN  \n",
      "2-gg              21.29     14.99 19.97  \n",
      "3-3dgs            21.37     15.32 20.16  \n",
      "4-dynamic 3dgs    21.16     15.39 19.93  \n",
      "5-ours            22.14     14.37 20.28  \n",
      "\\begin{tabular}{lrrrrrrrrr}\n",
      "\\toprule\n",
      "subset & \\multicolumn{9}{r}{2-test} \\\\\n",
      "eval_mode & \\multicolumn{3}{r}{1-gt} & \\multicolumn{3}{r}{2-cross-gt_0.6_5} & \\multicolumn{3}{r}{3-psnr} \\\\\n",
      "seg_type & 1-static & 2-dynamic & 3-all & 1-static & 2-dynamic & 3-all & 1-static & 2-dynamic & 3-all \\\\\n",
      "exp_name &  &  &  &  &  &  &  &  &  \\\\\n",
      "\\midrule\n",
      "1-sam & 54.51 & 32.77 & 50.69 & NaN & NaN & NaN & NaN & NaN & NaN \\\\\n",
      "2-gg & 35.68 & 30.76 & 34.81 & 23.79 & 11.33 & 21.58 & 21.29 & 14.99 & 19.97 \\\\\n",
      "3-3dgs & 55.67 & 39.61 & 52.86 & 51.29 & 18.67 & 45.49 & 21.37 & 15.32 & 20.16 \\\\\n",
      "4-dynamic 3dgs & 54.23 & 38.62 & 51.49 & 51.10 & 18.02 & 45.22 & 21.16 & 15.39 & 19.93 \\\\\n",
      "5-ours & 58.15 & 37.74 & 54.57 & 55.27 & 19.14 & 48.84 & 22.14 & 14.37 & 20.28 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "df = pd.concat([df_2dseg, df_psnr], axis=0)\n",
    "df = df.reset_index(drop=True)\n",
    "# df['values'] = df['mIoU'] if 'mIoU' in df.columns else df['psnr']\n",
    "# Perform the above line row by row\n",
    "df['values'] = df.apply(lambda x: x['mIoU'] if not math.isnan(x['mIoU']) else x['psnr'], axis=1)\n",
    "\n",
    "df = df.sort_values(by=\"exp_name\", ascending=False)\n",
    "df = df.sort_values(by=[\"subset\", 'eval_mode', \"seg_type\"], ascending=True)\n",
    "\n",
    "df = df.pivot(index=['exp_name'], columns=[\"subset\", 'eval_mode', \"seg_type\"], values=\"values\")\n",
    "\n",
    "# display float with 2 decimal places\n",
    "with pd.option_context('display.float_format', '{:.2f}'.format):\n",
    "    print(df)\n",
    "\n",
    "print(df.to_latex(escape=False, float_format=\"%.2f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
